# Adaptive Mini-RAG with Transformer-Based Retrieval Control

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**A smart RAG system that only retrieves when needed â€” reducing costs by 40-50%**

</div>

---

## ğŸ¯ The Problem

Traditional RAG systems **always retrieve documents**, even for simple questions like "What is 2+2?". This wastes:
- â±ï¸ **Time** - Unnecessary latency from retrieval operations
- ğŸ’° **Money** - API costs for vector store queries  
- âš¡ **Resources** - Wasted computational power

## âœ¨ The Solution

This project introduces an **adaptive retrieval controller** that:
- ğŸ§  Estimates model confidence using entropy
- âš–ï¸ Only retrieves when the model is uncertain
- ğŸ“‰ Reduces retrieval calls by 40-50%

---

## ğŸ“Š Results & Visualizations

<details>
<summary><b>ğŸ“ˆ Click to expand evaluation charts</b></summary>

<br>

### Accuracy vs Retrieval Calls
Shows that adaptive RAG maintains accuracy while significantly reducing retrieval calls.

![Accuracy vs Retrieval](assets/accuracy_vs_retrieval.png)

---

### Confidence Score Distribution
Red dots = queries that triggered retrieval, Green dots = no retrieval needed.

![Confidence Distribution](assets/confidence_entropy.png)

---

### Retrieval Decision Breakdown
How queries are distributed between retrieval and no-retrieval decisions.

![Retrieval Distribution](assets/retrieval_distribution.png)

---

### Cost Reduction
Total documents retrieved: Adaptive vs Baseline comparison.

![Cost Reduction](assets/cost_reduction.png)

</details>

---

## ğŸ—ï¸ Architecture

```
User Question
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer (Pass 1)        â”‚  â† No retrieval, just model
â”‚  Generate initial response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Confidence Estimator        â”‚  â† Entropy-based uncertainty
â”‚  High entropy = uncertain    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retrieval Controller        â”‚
â”‚  â”œâ”€ confidence > 0.7 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Answer directly âœ“
â”‚  â”œâ”€ 0.4 < conf â‰¤ 0.7 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Retrieve 3 docs
â”‚  â””â”€ confidence â‰¤ 0.4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Retrieve 5 docs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“ (if retrieval needed)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer (Pass 2)        â”‚  â† With retrieved context
â”‚  Final answer generation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

```bash
# Clone the repo
git clone https://github.com/BitsToBytes-Saksham/Adaptive-Mini-RAG.git
cd Adaptive-Mini-RAG

# Install dependencies
pip install -r requirements.txt

# Quick test (no training needed)
python inference.py --test

# Train the model
python train.py --epochs 10

# Ask questions
python inference.py --question "What is the speed of light?"

# Run full evaluation
python evaluate.py
```

---

## ğŸ“ Project Structure

```
Adaptive-Mini-RAG/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ embeddings.py      # Token + Positional embeddings
â”‚   â”œâ”€â”€ attention.py       # Multi-head self-attention (from scratch!)
â”‚   â””â”€â”€ transformer.py     # Full decoder-only transformer
â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ confidence.py      # Entropy-based confidence estimation
â”‚   â””â”€â”€ retrieval_controller.py
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ vector_store.py    # Cosine similarity search
â”‚   â””â”€â”€ retriever.py       # Top-k retrieval with logging
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents.txt      # 50 factual paragraphs
â”‚   â””â”€â”€ qa.json            # 100 Q&A pairs
â”œâ”€â”€ train.py               # Training pipeline
â”œâ”€â”€ inference.py           # Two-pass adaptive inference
â””â”€â”€ evaluate.py            # Metrics & visualizations
```

---

## ğŸ§  Key Technical Details

### Custom Transformer (No `nn.Transformer`!)

Built entirely from scratch using PyTorch primitives:

| Component | Implementation |
|-----------|----------------|
| Token Embeddings | Learnable embeddings with âˆšd scaling |
| Positional Encoding | Sinusoidal encodings |
| Multi-Head Attention | Q/K/V projections, scaled dot-product, causal mask |
| Feed-Forward | Two-layer MLP with GELU |
| Normalization | Pre-norm LayerNorm + residual connections |

### Confidence Estimation

```
Entropy = -Î£(p Ã— log(p))  over vocabulary

Confidence = 1 - (entropy / max_entropy)
```

High entropy â†’ Model is uncertain â†’ Retrieve more documents

---

## ğŸ“Š Evaluation Metrics

| Metric | Adaptive RAG | Baseline RAG |
|--------|--------------|--------------|
| Accuracy | ~85-90% | ~85-90% |
| Retrieval Rate | ~50-60% | 100% |
| **Cost Reduction** | **40-50%** | 0% |

---

## ğŸ”® Future Improvements

- [ ] Learned retrieval decision head (auxiliary loss)
- [ ] BPE tokenization (currently character-level)
- [ ] Cross-attention for retrieved documents
- [ ] Integration with external embedding models
- [ ] Latency benchmarking

---

## ğŸ“š References

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)
- [Self-RAG: Learning to Retrieve, Generate, and Critique](https://arxiv.org/abs/2310.11511)

---

## ğŸ“ License

MIT License - feel free to use and modify!

---

<div align="center">

**â­ Star this repo if you found it useful!**

Made with â¤ï¸ by [BitsToBytes-Saksham](https://github.com/BitsToBytes-Saksham)

</div>
